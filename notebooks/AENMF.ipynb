{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# go up one directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from functions import cosmic_val\n",
    "from models.aenmf import *\n",
    "from functions import cosmic_val\n",
    "from functions import data_handling as dh\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# set seed\n",
    "# np.random.seed(15)\n",
    "# torch.manual_seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/catalogues_Ovary_SBS.tsv\"\n",
    "cosmic_path = \"data/COSMIC_v3.4_SBS_GRCh37.txt\"\n",
    "output_folder = \"data/processed\"\n",
    "output_filename = \"Ordered_Ovary_SBS.csv\"\n",
    "ordered_cosmic_filename = \"ordered_cosmic.csv\"\n",
    "ordered_data_path = os.path.join(output_folder, output_filename)\n",
    "ordered_cosmic_path = os.path.join(output_folder, ordered_cosmic_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.load_preprocess_data(data_path, cosmic_path, sep1 = \"\\t\", sep2 = \"\\t\", output_folder = output_folder, output_filename = output_filename, out_cosmic_filename = ordered_cosmic_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(ordered_data_path, index_col = 0)\n",
    "cosmic = pd.read_csv(ordered_cosmic_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 523)\n",
      "(523, 4)\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM = 4\n",
    "TOLERANCE = 1e-10\n",
    "MAX_ITERATIONS = 100_000_000\n",
    "CONSTRAINT = 'abs'\n",
    "CRITERION = nn.MSELoss() # consider frobenius norm!\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "E_init = np.random.rand(data.shape[1], LATENT_DIM)\n",
    "\n",
    "print(E_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m aenmf_model \u001b[38;5;241m=\u001b[39m aenmf(input_dim \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     15\u001b[0m                           latent_dim \u001b[38;5;241m=\u001b[39m LATENT_DIM,\n\u001b[0;32m     16\u001b[0m                           constraint\u001b[38;5;241m=\u001b[39m CONSTRAINT,)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Training AENMF\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m aenmf_mod,training_loss_aenmf, signatures_aenmf, exposures_aenmf , enc_aenmf \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maenmf_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCRITERION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43maenmf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTOLERANCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mrelative_tol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMAX_ITERATIONS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Calculating signatures and exposures for NMF\u001b[39;00m\n\u001b[0;32m     28\u001b[0m diagonals_aenmf \u001b[38;5;241m=\u001b[39m signatures_nmf\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "signatures = []\n",
    "iterations = 1\n",
    "\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    # Train-test split (here it makes sense, we are working with AE)\n",
    "    train, test = train_test_split(data.T, test_size = 0.2)\n",
    "    train = train.T\n",
    "    test = test.T\n",
    "    print(type(train))\n",
    "\n",
    "    # Initializing AENMF model\n",
    "    aenmf_model = aenmf(input_dim = train.shape[1],\n",
    "                              latent_dim = LATENT_DIM,\n",
    "                              constraint= CONSTRAINT,)\n",
    "    # Training AENMF\n",
    "    aenmf_mod,training_loss_aenmf, signatures_aenmf, exposures_aenmf , enc_aenmf = train( \n",
    "                                                model = aenmf_model,\n",
    "                                                training_data = train,\n",
    "                                                criterion = CRITERION,\n",
    "                                                optimizer = optim.Adam(aenmf_model.parameters(), lr=1e-3),\n",
    "                                                tol = TOLERANCE,\n",
    "                                                relative_tol = True,\n",
    "                                                max_iter = MAX_ITERATIONS)\n",
    "    \n",
    "    # Calculating signatures and exposures for NMF\n",
    "    diagonals_aenmf = signatures_nmf.sum(axis=0)\n",
    "    exposures_aenmf = exposures_aenmf.T @ np.diag(diagonals_aenmf)\n",
    "    signatures_nmf = (signatures_nmf) @ np.diag(1 / diagonals_aenmf)\n",
    "    \n",
    "    losses_train.append(training_loss_aenmf[-1])\n",
    "    signatures.append(signatures_aenmf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses train:  18307.472785824662\n"
     ]
    }
   ],
   "source": [
    "print(\"Losses train: \", np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signatures = np.hstack(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam = KMedoids(n_clusters = LATENT_DIM, metric='cosine').fit(all_signatures.T)\n",
    "consensus_signatures = all_signatures[:, pam.medoid_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3\n",
      "0   0.005577  0.000000  0.025359  0.002142\n",
      "1   0.004096  0.001839  0.019929  0.003253\n",
      "2   0.000635  0.000027  0.003283  0.000454\n",
      "3   0.004077  0.012536  0.019291  0.014627\n",
      "4   0.003387  0.001560  0.015050  0.000395\n",
      "..       ...       ...       ...       ...\n",
      "91  0.051070  0.011481  0.000970  0.011779\n",
      "92  0.000640  0.001736  0.005946  0.021565\n",
      "93  0.000309  0.008897  0.004173  0.007547\n",
      "94  0.003936  0.001483  0.007071  0.003821\n",
      "95  0.015113  0.057556  0.003857  0.147273\n",
      "\n",
      "[96 rows x 4 columns]\n",
      "                SBS44    SBS10c    SBS40a        SBS10a\n",
      "Type                                                   \n",
      "A[C>A]A  7.680000e-18  0.004331  0.036395  2.190170e-03\n",
      "A[C>A]C  1.500380e-04  0.014830  0.016772  1.770137e-03\n",
      "A[C>A]G  9.160000e-07  0.000657  0.003748  1.500120e-04\n",
      "A[C>A]T  5.781465e-03  0.013128  0.015435  1.700132e-02\n",
      "A[C>G]A  3.180806e-03  0.000348  0.008213  2.230000e-16\n",
      "...               ...       ...       ...           ...\n",
      "T[T>C]T  3.710940e-02  0.019921  0.007913  3.250252e-03\n",
      "T[T>G]A  7.680000e-18  0.008731  0.005563  2.690209e-03\n",
      "T[T>G]C  7.680000e-18  0.000952  0.006422  2.230000e-16\n",
      "T[T>G]G  9.172320e-04  0.001108  0.004188  2.160000e-05\n",
      "T[T>G]T  9.002281e-03  0.025115  0.014928  1.890147e-02\n",
      "\n",
      "[96 rows x 4 columns]\n",
      "Shape of signatures_sorted:  (96, 4)\n",
      "Shape of signatures_true_sorted:  (96, 4)\n"
     ]
    }
   ],
   "source": [
    "match = cosmic_val.compute_match(consensus_signatures, cosmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted</th>\n",
       "      <th>True</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SBS44</td>\n",
       "      <td>0.839172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SBS10c</td>\n",
       "      <td>0.661057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SBS40a</td>\n",
       "      <td>0.721298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SBS10a</td>\n",
       "      <td>0.931474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Extracted    True  Similarity\n",
       "0          0   SBS44    0.839172\n",
       "1          1  SBS10c    0.661057\n",
       "2          2  SBS40a    0.721298\n",
       "3          3  SBS10a    0.931474"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7882502198463217\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(match['Similarity']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_GENOMICS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
