{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# go up one directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from functions import cosmic_val\n",
    "from models.nmf import NMF_mult_tol\n",
    "from functions import cosmic_val\n",
    "from sklearn.decomposition import NMF as nmf_sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_tsv_based_on_txt(tsv_file_path, txt_file_path, output_tsv_path):\n",
    "    # Read the .txt file to get the label order\n",
    "    with open(txt_file_path, 'r') as txt_file:\n",
    "        labels = txt_file.readline().strip().split('\\t')[1:]  # Skip the first column (Type)\n",
    "\n",
    "    # Read the .tsv file\n",
    "    tsv_df = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "\n",
    "    # Ensure the first column is the index\n",
    "    tsv_df.set_index(tsv_df.columns[0], inplace=True)\n",
    "\n",
    "    # Reorder the rows based on the labels from the .txt file\n",
    "    reordered_df = tsv_df.reindex(labels)\n",
    "\n",
    "    # Reset the index to make the first column a regular column again\n",
    "    reordered_df.reset_index(inplace=True)\n",
    "\n",
    "    # Save the reordered DataFrame to a new .tsv file\n",
    "    reordered_df.to_csv(output_tsv_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "def transform_first_column_to_index(df):\n",
    "    \"\"\"\n",
    "    Transforms the first column of a DataFrame into the index and drops it as a column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - Updated DataFrame with the first column as the index.\n",
    "    \"\"\"\n",
    "    # Set the first column as the index\n",
    "    df = df.set_index(df.columns[0])\n",
    "    \n",
    "    # Optionally rename the index (if needed)\n",
    "    df.index.name = None  # Set to `None` to remove the name\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def align_datasets_by_index(df1, df2):\n",
    "    \"\"\"\n",
    "    Aligns two DataFrames by their indices (row names), ensuring rows appear in the same order.\n",
    "\n",
    "    Parameters:\n",
    "    - df1: pandas DataFrame (first dataset)\n",
    "    - df2: pandas DataFrame (second dataset)\n",
    "\n",
    "    Returns:\n",
    "    - Aligned DataFrames (df1_aligned, df2_aligned)\n",
    "    \"\"\"\n",
    "    # Ensure both DataFrames have the same index and are sorted by index\n",
    "    df1_aligned = df1.loc[df1.index.sort_values()]\n",
    "    df2_aligned = df2.loc[df1_aligned.index]  # Reorder df2 to match df1's index\n",
    "\n",
    "    # Check if indices are perfectly aligned (optional)\n",
    "    assert (df1_aligned.index == df2_aligned.index).all(), \"Indices are not perfectly aligned!\"\n",
    "\n",
    "    return df1_aligned, df2_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"data/catalogues_Ovary_SBS.tsv\", sep=\"\\t\")\n",
    "\n",
    "cosmic = pd.read_csv(\"data/COSMIC_v3.4_SBS_GRCh37.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic = cosmic.set_index(cosmic.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic, data = align_datasets_by_index(cosmic, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 523)\n",
      "(523, 4)\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM = 4\n",
    "TOLERANCE = 1e-10\n",
    "MAX_ITERATIONS = 100_000_000\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "E_init = np.random.rand(data.shape[1], LATENT_DIM)\n",
    "\n",
    "print(E_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "signatures = []\n",
    "iterations = 5\n",
    "\n",
    "\n",
    "# for i in tqdm(range(iterations)):\n",
    "    \n",
    "#     # Applying NMF\n",
    "#     signatures_nmf, exposures_nmf, loss_nmf, _, _, n_iter_nmf = NMF_mult_tol(data.to_numpy(),\n",
    "#                                                                              rank = LATENT_DIM,\n",
    "#                                                                              tol = TOLERANCE,\n",
    "#                                                                              mse=True,\n",
    "#                                                                              G_0 = E_init.T)\n",
    "\n",
    "#     # Calculating signatures and exposures for NMF\n",
    "#     diagonals_nmf = signatures_nmf.sum(axis=0)\n",
    "#     exposures_nmf = exposures_nmf.T @ np.diag(diagonals_nmf)\n",
    "#     signatures_nmf = (signatures_nmf) @ np.diag(1 / diagonals_nmf)\n",
    "    \n",
    "#     losses_train.append(loss_nmf[-1])\n",
    "#     signatures.append(signatures_nmf)\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "\n",
    "    # Sklearn NMF\n",
    "\n",
    "    nmf = nmf_sklearn(n_components = LATENT_DIM, init = 'random', random_state = 0, max_iter = MAX_ITERATIONS, tol = TOLERANCE)\n",
    "\n",
    "    signatures_nmf = nmf.fit_transform(data)\n",
    "    exposures_nmf = nmf.components_\n",
    "    loss = nmf.reconstruction_err_\n",
    "\n",
    "    diagonals_nmf = signatures_nmf.sum(axis=0)\n",
    "    exposures_nmf = exposures_nmf.T @ np.diag(diagonals_nmf)\n",
    "    signatures_nmf = (signatures_nmf) @ np.diag(1 / diagonals_nmf)\n",
    "    \n",
    "    losses_train.append(loss)\n",
    "    signatures.append(signatures_nmf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses train:  18282.915131557565\n"
     ]
    }
   ],
   "source": [
    "print(\"Losses train: \", np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signatures:  (5, 96, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Signatures: \", np.shape(signatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signatures = np.hstack(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_test = signatures[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4)\n"
     ]
    }
   ],
   "source": [
    "print(signature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicovis/anaconda3/envs/DL_GENOMICS/lib/python3.12/site-packages/sklearn_extra/cluster/_k_medoids.py:329: UserWarning: Cluster 2 is empty! self.labels_[self.medoid_indices_[2]] may not be labeled with its corresponding cluster (2).\n",
      "  warnings.warn(\n",
      "/home/nicovis/anaconda3/envs/DL_GENOMICS/lib/python3.12/site-packages/sklearn_extra/cluster/_k_medoids.py:329: UserWarning: Cluster 3 is empty! self.labels_[self.medoid_indices_[3]] may not be labeled with its corresponding cluster (3).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pam = KMedoids(n_clusters = LATENT_DIM, metric='cosine').fit(all_signatures.T)\n",
    "consensus_signatures = all_signatures[:, pam.medoid_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4)\n"
     ]
    }
   ],
   "source": [
    "print(consensus_signatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3\n",
      "0   0.002184  0.025966  0.000509  0.005513\n",
      "1   0.003262  0.020346  0.002051  0.004107\n",
      "2   0.000454  0.003366  0.000077  0.000600\n",
      "3   0.014658  0.019393  0.011910  0.004072\n",
      "4   0.000426  0.015425  0.001735  0.003396\n",
      "..       ...       ...       ...       ...\n",
      "91  0.011512  0.000742  0.014445  0.051129\n",
      "92  0.021356  0.005459  0.001607  0.000646\n",
      "93  0.007595  0.004089  0.008242  0.000296\n",
      "94  0.003791  0.007145  0.001676  0.003943\n",
      "95  0.146347  0.000000  0.053967  0.015041\n",
      "\n",
      "[96 rows x 4 columns]\n",
      "               SBS10a      SBS3    SBS10c         SBS44\n",
      "Type                                                   \n",
      "A[C>A]A  2.190170e-03  0.020808  0.004331  7.680000e-18\n",
      "A[C>A]C  1.770137e-03  0.016507  0.014830  1.500380e-04\n",
      "A[C>A]G  1.500120e-04  0.001751  0.000657  9.160000e-07\n",
      "A[C>A]T  1.700132e-02  0.012205  0.013128  5.781465e-03\n",
      "A[C>G]A  2.230000e-16  0.019708  0.000348  3.180806e-03\n",
      "...               ...       ...       ...           ...\n",
      "T[T>C]T  3.250252e-03  0.013906  0.019921  3.710940e-02\n",
      "T[T>G]A  2.690209e-03  0.007253  0.008731  7.680000e-18\n",
      "T[T>G]C  2.230000e-16  0.006283  0.000952  7.680000e-18\n",
      "T[T>G]G  2.160000e-05  0.008053  0.001108  9.172320e-04\n",
      "T[T>G]T  1.890147e-02  0.010504  0.025115  9.002281e-03\n",
      "\n",
      "[96 rows x 4 columns]\n",
      "Shape of signatures_sorted:  (96, 4)\n",
      "Shape of signatures_true_sorted:  (96, 4)\n"
     ]
    }
   ],
   "source": [
    "match = cosmic_val.compute_match(signature_test, cosmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted</th>\n",
       "      <th>True</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SBS10a</td>\n",
       "      <td>0.931109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SBS3</td>\n",
       "      <td>0.713532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SBS10c</td>\n",
       "      <td>0.650058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SBS44</td>\n",
       "      <td>0.839054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Extracted    True  Similarity\n",
       "0          0  SBS10a    0.931109\n",
       "1          1    SBS3    0.713532\n",
       "2          2  SBS10c    0.650058\n",
       "3          3   SBS44    0.839054"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_GENOMICS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
