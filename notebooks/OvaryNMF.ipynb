{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# go up one directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from functions import cosmic_val\n",
    "from models.nmf import nmf\n",
    "from functions import cosmic_val\n",
    "from functions import data_handling as dh\n",
    "\n",
    "# set seed\n",
    "# np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/catalogues_Ovary_SBS.tsv\"\n",
    "cosmic_path = \"data/COSMIC_v3.4_SBS_GRCh37.txt\"\n",
    "output_folder = \"data/processed\"\n",
    "output_filename = \"Ordered_Ovary_SBS.csv\"\n",
    "ordered_data_path = os.path.join(output_folder, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists in  data/processed/Ordered_Ovary_SBS.csv\n"
     ]
    }
   ],
   "source": [
    "dh.load_preprocess_data(data_path, cosmic_path, sep1 = \"\\t\", sep2 = \"\\t\", output_folder = output_folder, output_filename = output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(ordered_data_path, index_col = 0)\n",
    "cosmic = pd.read_csv(cosmic_path, sep = \"\\t\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 4\n",
    "TOLERANCE = 1e-4\n",
    "MAX_ITERATIONS = 100_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, Loss: 33154.52353135035\n",
      "Iteration: 2000, Loss: 28161.85573259711\n",
      "Iteration: 3000, Loss: 26427.429519980473\n",
      "Iteration: 4000, Loss: 25719.453729811798\n",
      "Iteration: 5000, Loss: 25502.351944073755\n",
      "Iteration: 6000, Loss: 25371.92485494772\n",
      "Iteration: 7000, Loss: 25211.088473150456\n",
      "Iteration: 8000, Loss: 25012.534101918405\n",
      "Iteration: 9000, Loss: 24544.367858880974\n",
      "Iteration: 10000, Loss: 24006.00058179592\n",
      "Iteration: 11000, Loss: 22205.63691487846\n",
      "Iteration: 12000, Loss: 19484.102019937898\n",
      "Iteration: 13000, Loss: 18698.20472974728\n",
      "Iteration: 14000, Loss: 18544.3602020063\n",
      "Iteration: 15000, Loss: 18482.42500907173\n",
      "Iteration: 16000, Loss: 18473.041942140713\n",
      "Iteration: 17000, Loss: 18463.28133169108\n",
      "Iteration: 18000, Loss: 18452.927174018034\n",
      "Iteration: 19000, Loss: 18434.152630659977\n",
      "Iteration: 20000, Loss: 18430.62139323773\n",
      "Iteration: 21000, Loss: 18413.935297675027\n",
      "Iteration: 22000, Loss: 18387.001807071636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:52<00:00, 52.17s/it]\n"
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "signatures = []\n",
    "iterations = 1\n",
    "\n",
    "\n",
    "for i in tqdm(range(iterations)):\n",
    "    \n",
    "    # Applying NMF\n",
    "    signatures_nmf, exposures_nmf, loss_nmf = nmf(catalog_matrix = data.to_numpy(),\n",
    "                                                  num_sign = LATENT_DIM,\n",
    "                                                  tol = TOLERANCE,\n",
    "                                                  max_iter = MAX_ITERATIONS)\n",
    "    \n",
    "    # Calculating signatures and exposures for NMF\n",
    "    diagonals_nmf = signatures_nmf.sum(axis=0)\n",
    "    exposures_nmf = exposures_nmf.T @ np.diag(diagonals_nmf)\n",
    "    signatures_nmf = (signatures_nmf) @ np.diag(1 / diagonals_nmf)\n",
    "    \n",
    "    losses_train.append(loss_nmf[-1])\n",
    "    signatures.append(signatures_nmf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses train:  18386.26231605195\n"
     ]
    }
   ],
   "source": [
    "print(\"Losses train: \", np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signatures = np.hstack(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam = KMedoids(n_clusters = LATENT_DIM, metric='cosine').fit(all_signatures.T)\n",
    "consensus_signatures = all_signatures[:, pam.medoid_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_signatures, mean_similarity = cosmic_val.compute_match(consensus_signatures, cosmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Extracted    True  Similarity\n",
      "0          0   SBS44    0.842920\n",
      "1          1  SBS10c    0.743205\n",
      "2          2  SBS10a    0.931570\n",
      "3          3  SBS40a    0.728419\n",
      "Mean similarity of the matched signatures:  0.8115285506351773\n"
     ]
    }
   ],
   "source": [
    "print(matched_signatures.head())\n",
    "print(\"\\nMean similarity of the matched signatures: \", mean_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_GENOMICS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
